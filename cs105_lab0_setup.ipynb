{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "# **Running Your First Notebook**\n",
    "This notebook will show you how to install the course libraries, create your first Spark cluster, and test basic notebook funcionality.  To move through the notebook just run each of the cells.  You will not need to solve any problems to complete this lab.  You can run a cell by pressing \"shift-enter\", which will compute the current cell and advance to the next cell, or by clicking in a cell and pressing \"control-enter\", which will compute the current cell and remain in that cell.\n",
    "\n",
    "** This notebook covers: **\n",
    "* *Part 1:* Attach class helper library\n",
    "* *Part 2:* Test Spark functionality\n",
    "* *Part 3:* Test class helper library\n",
    "* *Part 4:* Check plotting\n",
    "* *Part 5:* Check MathJax formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Part 1: Attach and test class helper library **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1a) Install class helper library into your Databricks CE workspace\n",
    "- The class helper library \"spark_mooc_meta\" is published in the [PyPI Python Package repository](https://pypi.python.org/pypi) as [https://pypi.python.org/pypi/spark_mooc_meta](https://pypi.python.org/pypi/spark_mooc_meta)\n",
    "- You can install the library into your workspace following the following instructions:\n",
    " - Step 1: Click on \"Workspace\", then on the dropdown and select \"Create\" and \"Library\"\n",
    "\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_Library1.png\" alt=\"Drawing\" />\n",
    " - Step 2 Enter the name of the library by selecting \"Upload Python Egg or PyPI\" and entering \"spark_mooc_meta\" in the \"PyPI Name\" field\n",
    "\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_Library2.png\" alt=\"Drawing\" />\n",
    " - Step 3 Make sure the checkbox for auto-attaching the library to your cluster is selected\n",
    "\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_Library3.png\" alt=\"Drawing\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Part 1: Test Spark functionality **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (1a) Create a DataFrame and filter it **\n",
    "\n",
    "When you run the next cell (with control-enter or shift-enter), you will see the following popup.\n",
    "\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_Cluster.png\" alt=\"Drawing\" />\n",
    "\n",
    "Select the click box and then \"Launch and Run\". The display at the top of your notebook will change to \"Pending\"\n",
    "\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_Cluster_Pending.png\" alt=\"Drawing\" />\n",
    "\n",
    "Note that it may take a few seconds to a few minutes to start your cluster. Once your cluster is running the display will changed to \"Attached\"\n",
    "\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_Cluster_Attached.png\" alt=\"Drawing\" />\n",
    "\n",
    "Congratulations! You just launched your Spark cluster in the cloud!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name=u'Bill', age=4)]\n"
     ]
    }
   ],
   "source": [
    "# Check that Spark is working\n",
    "from pyspark.sql import Row\n",
    "data = [('Alice', 1), ('Bob', 2), ('Bill', 4)]\n",
    "df = sqlContext.createDataFrame(data, ['name', 'age'])\n",
    "fil = df.filter(df.age > 3).collect()\n",
    "print fil\n",
    "\n",
    "# If the Spark job doesn't work properly this will raise an AssertionError\n",
    "assert fil == [Row(u'Bill', 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (2b) Loading a text file **\n",
    "\n",
    "Let's load a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124787\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5aafdff1fbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# If the text file didn't load properly an AssertionError will be raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mshakespeareCount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m122395\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check loading data with sqlContext.read.text\n",
    "import os.path\n",
    "baseDir = os.path.join('databricks-datasets', 'cs100')\n",
    "inputPath = os.path.join('lab1', 'data-001', 'shakespeare.txt')\n",
    "fileName1 = os.path.join(baseDir, inputPath)\n",
    "fileName=\"shakespeare.txt\"\n",
    "dataDF = sqlContext.read.text(fileName)\n",
    "shakespeareCount = dataDF.count()\n",
    "\n",
    "print shakespeareCount\n",
    "\n",
    "# If the text file didn't load properly an AssertionError will be raised\n",
    "assert shakespeareCount == 122395"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Part 3: Test class testing library **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (3a) Compare with hash **\n",
    "\n",
    "Run the following cell. If you see an **ImportError**, you should verify that you added the spark_mooc_meta library to your cluster and, if necessary, repeat step (1a).\n",
    "\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_LibraryError.png\" alt=\"Drawing\"  style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Compare with hash (2a)\n",
    "# Check our testing library/package\n",
    "# This should print '1 test passed.' on two lines\n",
    "from databricks_test_helper import Test\n",
    "\n",
    "twelve = 12\n",
    "Test.assertEquals(twelve, 12, 'twelve should equal 12')\n",
    "Test.assertEqualsHashed(twelve, '7b52009b64fd0a2a49e6d8a939753077792b0554',\n",
    "                        'twelve, once hashed, should equal the hashed value of 12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (3b) Compare lists **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Compare lists (2b)\n",
    "# This should print '1 test passed.'\n",
    "unsortedList = [(5, 'b'), (5, 'a'), (4, 'c'), (3, 'a')]\n",
    "Test.assertEquals(sorted(unsortedList), [(3, 'a'), (4, 'c'), (5, 'a'), (5, 'b')],\n",
    "                  'unsortedList does not sort properly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Part 4: Check plotting **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (3a) Our first plot **\n",
    "\n",
    "After executing the code cell below, you should see a plot with 50 blue circles.  The circles should start at the bottom left and end at the top right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-69b5d62e9319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'$range(1, 50)$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'$\\log_e(x^2)$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#display(fig) #in databricks notebooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'show' is not defined"
     ]
    }
   ],
   "source": [
    "# Check matplotlib plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from math import log\n",
    "\n",
    "# function for generating plot layout\n",
    "def preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999', gridWidth=1.0):\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n",
    "    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
    "    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
    "        axis.set_ticks_position('none')\n",
    "        axis.set_ticks(ticks)\n",
    "        axis.label.set_color('#999999')\n",
    "        if hideLabels: axis.set_ticklabels([])\n",
    "    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
    "    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
    "    return fig, ax\n",
    "\n",
    "# generate layout and plot data\n",
    "x = range(1, 50)\n",
    "y = [log(x1 ** 2) for x1 in x]\n",
    "fig, ax = preparePlot(range(5, 60, 10), range(0, 12, 1))\n",
    "plt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\n",
    "ax.set_xlabel(r'$range(1, 50)$'), ax.set_ylabel(r'$\\log_e(x^2)$')\n",
    "#display(fig) #in databricks notebooks\n",
    "plt.show()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Part 5: Check MathJax formulas **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (5a) Gradient descent formula **\n",
    "\n",
    "You should see a formula on the line below this one: \\\\[ \\scriptsize \\mathbf{w}_{i+1} = \\mathbf{w}_i - \\alpha_i \\sum_j (\\mathbf{w}_i^\\top\\mathbf{x}_j  - y_j) \\mathbf{x}_j \\,.\\\\]\n",
    "\n",
    "This formula is included inline with the text and is \\\\( \\scriptsize (\\mathbf{w}^\\top \\mathbf{x} - y) \\mathbf{x} \\\\)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (5b) Log loss formula **\n",
    "\n",
    "This formula shows log loss for single point. Log loss is defined as: \\\\[  \\scriptsize \\ell_{log}(p, y) = \\begin{cases} -\\log (p) & \\text{if } y = 1 \\\\\\ -\\log(1-p) & \\text{if } y = 0 \\end{cases} \\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have completed the lab!\n",
    "\n",
    "Return to the edX website and proceed with the page for registering with the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "name": "cs105_lab0",
  "notebookId": 2197894340707400
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
